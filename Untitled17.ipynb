{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef96b7fc",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d3abc",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d46865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542b2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769ea69",
   "metadata": {},
   "source": [
    "Now we will download the webDriver for the Web Browser Steps for thr download are 1 Check the version of your browser \n",
    "2 go to the link https://chromedriver.chromium.org/downloads 3 Download the webdriver for your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d19ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251c1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6bab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b822c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the shine page an automated chrome browser \n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b48f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggester-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input)\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7435f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.Class_NAME,\"Search form\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44eb783",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title[]\n",
    "job_location[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw_tupple\"/div/a')\n",
    "for i in title_tag:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping Job location from the given page \n",
    "location_tags=driver.find_elements(By.Xpath,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')                                   \n",
    "for i in location_tags:\n",
    "     location=i.text\n",
    "job_location.append(location) \n",
    "\n",
    "#scraping Comopany name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//span[@class=\"comp-dtls-wrap\"]/a[1]')\n",
    "for i in company_tags:\n",
    "     company=i.text\n",
    "company_name.append(compony)\n",
    "\n",
    "#scraping Job Experience from the given page                              \n",
    "job Experience_tags=driver.find_elements(By.Xpath,'//span[@class=\"expwdth\"]\n",
    "for i in jobExperience_tags:\n",
    "     job experience=i.text\n",
    "job_exprience.append(location) \n",
    "                                   \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title),len(job_location)\n",
    "      20 20 20 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6175146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.Dataframe({'Title':job_title,'Location':job_location,'Compony_name':compony_name,'Experience':experience_required}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451b9e8",
   "metadata": {},
   "source": [
    "2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6420b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the shine page an automated chrome browser \n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,)\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title[]\n",
    "job_location[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw_tupple\"/div/a')\n",
    "for i in title_tag:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping Job location from the given page \n",
    "location_tags=driver.find_elements(By.Xpath,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for i in location_tags:\n",
    "     location=i.text\n",
    "job_location.append(location) \n",
    "\n",
    "#scraping Comopany name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//span[@class=\"comp-dtls-wrap\"]/a[1]')\n",
    "for i in company_tags:\n",
    "     company=i.text\n",
    "company_name.append(compony)\n",
    "\n",
    "#scraping Job Experience from the given page                              \n",
    "job Experience_tags=driver.find_elements(By.Xpath,'//span[@class=\"expwdth\"]\n",
    "for i in jobExperience_tags:\n",
    "     job experience=i.text\n",
    "job_exprience.append(location) \n",
    "                                   \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title),len(job_location)\n",
    "      20 20 20 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.Dataframe({'Title':job_title,'Location':job_location,'Compony_name':compony_name,'Experience':experience_required}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190b8df",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the shine page an automated chrome browser \n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fec9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da007393",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,)\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae728113",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title[]\n",
    "job_location[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c385fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw_tupple\"/div/a')\n",
    "for i in title_tag:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping Job location from the given page \n",
    "location_tags=driver.find_elements(By.Xpath,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for i in location_tags:\n",
    "     location=i.text\n",
    "job_location.append(location) \n",
    "\n",
    "#scraping Comopany name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//span[@class=\"comp-dtls-wrap\"]/a[1]')\n",
    "for i in company_tags:\n",
    "     company=i.text\n",
    "company_name.append(compony)\n",
    "\n",
    "#scraping Job Experience from the given page                              \n",
    "job Experience_tags=driver.find_elements(By.Xpath,'//span[@class=\"expwdth\"\n",
    "for i in jobExperience_tags:\n",
    "     job experience=i.text\n",
    "job_exprience.append(location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title),len(job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.Dataframe({'Title':job_title,'Location':job_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7720f",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. Product Description\n",
    "8. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "o scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a33e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1023fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page an automated chrome browser \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6951c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering sunglass and brand price as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"<div class=\"_2WkVRV\">OCHILA</div>\n",
    "designation.send_keys('Sunglass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,)\n",
    "location.send_keys('sunglass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b8e11",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-\n",
    "reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "place=FLIPKAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page an automated chrome browser \n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-\n",
    "reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "place=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering rating review summary and full review as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"div class\"\n",
    "designation.send_keys('review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3672ba7",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcff070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8dd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba87b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page an automated chrome browser \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering Brand product description and price as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"<div class=\"_2WkVRV\">URBANBOX</div>\n",
    "designation.send_keys('review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7920fe1",
   "metadata": {},
   "source": [
    "Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then\n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36288b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc212fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab57043",
   "metadata": {},
   "outputs": [],
   "source": [
    "Opening the amazon page an automated chrome browser \n",
    "driver.get(\" https://www.amazon.in/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering laptop and cpu as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME<span class=\"a-size-medium a-color-base\">MSI</span>\n",
    "designation.send_keys('review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b560f2a",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on Top Quote\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe05c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fddec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Opening the amazon page an automated chrome browser \n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e02e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering Quote Author and type of quate as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME<a class=\"title\" href=\"/quote/99150\">Failure is simply the opportunity to begin again, this time more intelligently.</a>\n",
    "designation.send_keys('review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b5611",
   "metadata": {},
   "source": [
    "\n",
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc65c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3171fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the amazon page an automated chrome browser \n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering prime minister name born dead term of office as required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME\n",
    "designation.send_keys('review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6a5df",
   "metadata": {},
   "source": [
    "\n",
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe.\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6883db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b306b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering top 50 most expensive car required in the question \n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME<a href=\"/features/308149/most-expensive-new-cars-ever/\">50 Most Expensive Cars In The World</a>\n",
    "designation.send_keys('review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af6068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
